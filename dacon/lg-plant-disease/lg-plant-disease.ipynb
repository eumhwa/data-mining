{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lg-plant-disease.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPo/2f3d4uT01bGL/XgzYdl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"xEZ2EwcaDILz"},"outputs":[],"source":["import os\n","exp_id = 13"]},{"cell_type":"code","source":["import json, math, random\n","from glob import glob\n","\n","import ray\n","from ray import train\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import cv2\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torchvision import models\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset\n","\n","from transformers import ViTFeatureExtractor, ViTModel, ViTForImageClassification, ViTConfig"],"metadata":{"id":"cYooZITlDam-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = \"/usr/src/coco/dacon/lg/data\"\n","sample = glob(f'{data_path}/train/*')[5]\n","\n","sample_csv = pd.read_csv(glob(sample+'/*.csv')[0])\n","sample_image = cv2.imread(glob(sample+'/*.jpg')[0])\n","sample_json = json.load(open(glob(sample+'/*.json')[0], 'r'))\n","train_df = pd.read_csv(f'{data_path}/train.csv')"],"metadata":{"id":"8UJJTuKsDapU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sample_csv.describe() "],"metadata":{"id":"EPklZN-1Datq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n","                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n","\n","crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n","disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n","           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n","           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n","           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n","           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n","           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n","risk = {'1':'초기','2':'중기','3':'말기'}\n"],"metadata":{"id":"ROWD2Zn9DawY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_description_sub = {}\n","for key, value in disease.items():\n","    label_description_sub[f'{key}_00_0'] = f'{crop[key]}_정상'\n","    for disease_code in value:\n","        label = f'{key}_{disease_code}'\n","        label_description_sub[label] = f'{crop[key]}_{disease[key][disease_code]}'\n","print(list(label_description_sub.items())[-5:])\n","print(len(label_description_sub))\n","\n","label_description = {}\n","for key, value in disease.items():\n","    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n","    for disease_code in value:\n","        for risk_code in risk:\n","            label = f'{key}_{disease_code}_{risk_code}'\n","            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n","# list(label_description.items())[:3]\n","\n","target_label_description = {}\n","for c in sorted(train_df.label.unique()):\n","    target_label_description[c] = label_description[c]\n","\n","print('n label : ', len(target_label_description))"],"metadata":{"id":"cPRRpb_sDbBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_encoder = {key:idx for idx, key in enumerate(target_label_description)}\n","label_decoder = {val:key for key, val in label_encoder.items()}"],"metadata":{"id":"NegBmAO3DbDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_new_feature(df):\n","    new_df = df.copy()\n","    new_df[\"new_temp\"] = (new_df[\"내부 온도 1 최고\"]-new_df[\"내부 온도 1 최저\"])/(new_df[\"내부 온도 1 평균\"] + 0.001)\n","    new_df[\"new_hum\"] = (new_df[\"내부 습도 1 최고\"]-new_df[\"내부 습도 1 최저\"])/(new_df[\"내부 습도 1 평균\"] + 0.001)\n","    new_df[\"new_dew\"] = (new_df[\"내부 이슬점 최고\"]-new_df[\"내부 이슬점 최저\"])/(new_df[\"내부 이슬점 평균\"] + 0.001)\n","#     cols = new_df.columns.tolist() + [c+\"_\" for c in new_df.columns.tolist()]\n","    \n","    ary = new_df.values\n","    if ary.shape[0] > 1:\n","        new_ary = []\n","        for i in range(ary.shape[0]-1):\n","            tmp = ary[i].tolist() + ary[i+1].tolist()\n","            new_ary.append(tmp)\n","    else:\n","        new_ary = [ary.tolist()[0] + [0]*new_df.shape[1]]\n","        \n","    return pd.DataFrame(np.array(new_ary))\n","    \n","class CustomDataset(Dataset):\n","    def __init__(self, files, max_len, labels=None, transform=None, csv_cols=[], mode='train'):\n","        self.mode = mode\n","        self.files = files\n","        self.csv_feature_dict = csv_cols\n","        self.csv_feature_check = [0]*len(self.files)\n","        self.csv_features = [None]*len(self.files)\n","        self.max_len = max_len # 24 * 6 * 2\n","        self.label_encoder = label_encoder\n","        self.transform = transform\n","        self.debug_df = None\n","\n","    def __len__(self):\n","        return len(self.files)\n","    \n","    def __getitem__(self, i):\n","        file = self.files[i]\n","        file_name = file.split('/')[-1]\n","        \n","        # csv\n","        if self.csv_feature_check[i] == 0:\n","            csv_path = f'{file}/{file_name}.csv'\n","            df = pd.read_csv(csv_path)[self.csv_feature_dict]\n","            df = df.replace('-', None)\n","            \n","            # MinMax scaling\n","            for col in df.columns:\n","                if df[col].dtype != np.float64:\n","                    df[col] = pd.to_numeric(df[col])\n","                tmp_col = df[col].copy()\n","                if tmp_col.isna().sum() > 0:\n","                    tmp_col = tmp_col.interpolate(method='linear') \n","                tmp_col /= 100\n","                tmp_col.loc[tmp_col>1] = 1.0\n","                df[col] = tmp_col\n","            \n","            # new feature addition and zero padding\n","            df = create_new_feature(df)\n","            self.debug_df = file\n","            csv_feature = np.zeros((self.max_len, len(df.columns)))\n","            length = min(self.max_len, len(df))\n","            csv_feature[-length:] = df.to_numpy()[-length:]\n","            \n","            # csv_feature = df.values # shape (588, 9)\n","            self.csv_features[i] = csv_feature\n","            self.csv_feature_check[i] = 1\n","        else:\n","            csv_feature = self.csv_features[i]\n","        \n","        # image\n","        img_path = f'{file}/{file_name}.jpg'\n","        img = Image.open(img_path).convert(\"RGB\")\n","        # img = self.transform(img)\n","        \n","        if self.mode == 'train':\n","            img = self.transform(img)\n","            \n","            json_path = f'{file}/{file_name}.json'\n","            with open(json_path, 'r') as f:\n","                json_file = json.load(f)\n","            \n","            crop = json_file['annotations']['crop']\n","            disease = json_file['annotations']['disease']\n","            risk = json_file['annotations']['risk']\n","            label = f'{crop}_{disease}_{risk}'\n","            \n","            return {\n","                'img' : img, #torch.tensor(img, dtype=torch.float32),\n","                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n","                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n","            }\n","        else:\n","            img_tta0 = self.transform[0](img)\n","            img_tta1 = self.transform[1](img)\n","            img_tta2 = self.transform[2](img)\n","            return {\n","                'img' : img_tta0, #torch.tensor(img, dtype=torch.float32),\n","                'img_tta1' : img_tta1,\n","                'img_tta2' : img_tta2,\n","                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n","            }\n","        \n","class CustomDataset_old(Dataset):\n","    def __init__(self, files, max_len, labels=None, transform=None, csv_cols=[], mode='train'):\n","        self.mode = mode\n","        self.files = files\n","        self.csv_feature_dict = csv_cols\n","        self.csv_feature_check = [0]*len(self.files)\n","        self.csv_features = [None]*len(self.files)\n","        self.max_len = max_len # 24 * 6 * 2\n","        self.label_encoder = label_encoder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.files)\n","    \n","    def __getitem__(self, i):\n","        file = self.files[i]\n","        file_name = file.split('/')[-1]\n","        \n","        # csv\n","        if self.csv_feature_check[i] == 0:\n","            csv_path = f'{file}/{file_name}.csv'\n","            df = pd.read_csv(csv_path)[self.csv_feature_dict]\n","            df = df.replace('-', None)\n","            # MinMax scaling\n","            for col in df.columns:\n","                if df[col].dtype != np.float64:\n","                    df[col] = pd.to_numeric(df[col])\n","                tmp_col = df[col].copy()\n","                if tmp_col.isna().sum() > 0:\n","                    tmp_col = tmp_col.interpolate(method='linear')\n","                tmp_col /= 100\n","                tmp_col.loc[tmp_col>1] = 1.0\n","                df[col] = tmp_col\n","            \n","            # zero padding\n","            csv_feature = np.zeros((self.max_len, len(df.columns)))\n","            length = min(self.max_len, len(df))\n","            csv_feature[-length:] = df.to_numpy()[-length:]\n","            \n","            # csv_feature = df.values # shape (588, 9)\n","            self.csv_features[i] = csv_feature\n","            self.csv_feature_check[i] = 1\n","        else:\n","            csv_feature = self.csv_features[i]\n","        \n","        # image\n","        img_path = f'{file}/{file_name}.jpg'\n","        img = Image.open(img_path).convert(\"RGB\")\n","        img = self.transform(img)\n","        \n","        if self.mode == 'train':\n","            json_path = f'{file}/{file_name}.json'\n","            with open(json_path, 'r') as f:\n","                json_file = json.load(f)\n","            \n","            crop = json_file['annotations']['crop']\n","            disease = json_file['annotations']['disease']\n","            risk = json_file['annotations']['risk']\n","            label = f'{crop}_{disease}_{risk}'\n","            \n","            return {\n","                'img' : img, #torch.tensor(img, dtype=torch.float32),\n","                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n","                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n","            }\n","        else:\n","            return {\n","                'img' : img, #torch.tensor(img, dtype=torch.float32),\n","                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n","            }"],"metadata":{"id":"Vyh7von8DbGQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset Preparing"],"metadata":{"id":"7dAp0ucUDz_t"}},{"cell_type":"code","source":["seed = 1000\n","\n","train = sorted(glob(f'{data_path}/train/*'))\n","test = sorted(glob(f'{data_path}/test/*'))\n","\n","labels = pd.read_csv(f'{data_path}/train.csv')['label']\n","print(labels.value_counts())  "],"metadata":{"id":"G0mHtFyBDbJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# labelsss.value_counts()\n","# parameters\n","pretrained_architecture = [\n","    \"google/vit-base-patch16-224-in21k\" ,'google/vit-base-patch16-224', 'google/vit-base-patch16-384'\n","]\n","pretrained_architecture = pretrained_architecture[0]\n","\n","w = int(pretrained_architecture.split(\"-\")[3])\n","img_size = (w, w) #(384, 384)\n","scale_val = 0.95\n","\n","batch_size = 16\n","n_classes = len(label_encoder)\n","max_len= 24 * 6 * 2\n"],"metadata":{"id":"NlbqwBPrDbMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["compose_list = [\n","    transforms.Resize(img_size), \n","    transforms.ColorJitter(brightness=0.5), \n","    transforms.RandomHorizontalFlip(), \n","    transforms.RandomResizedCrop(\n","        img_size, scale=(scale_val, 1), ratio=(scale_val, 1)\n","        ),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","]\n","\n","train_transform = transforms.Compose(compose_list)\n","test_transform = transforms.Compose([compose_list[0]]+compose_list[-2:])"],"metadata":{"id":"oEs4vpxHDbPI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Network defining"],"metadata":{"id":"dPzmH12yD3Cq"}},{"cell_type":"code","source":["print(f\"using pretrained architecture : {pretrained_architecture}\")\n","\n","class ViTEncoder(nn.Module):\n","    def __init__(self):\n","        super(ViTEncoder, self).__init__()\n","        # self.feature_extractor = ViTFeatureExtractor.from_pretrained(pretrained_architecture)\n","        self.vit = ViTModel.from_pretrained(pretrained_architecture, output_attentions=False, add_pooling_layer=False)\n","        \n","    def forward(self, x):\n","        outputs = self.vit(x)\n","        seq_output = outputs[0][:, 0, :]\n","        return seq_output\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout, max_len):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        pe = pe.transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x): # x shape: [bs, seq_len, embedding_dim]\n","        # x = x + self.pe[:x.size(0)]\n","        x = x + self.pe[:, :x.size(1)]\n","        return self.dropout(x)\n","    \n","class TSTransformer(nn.Module):\n","    def __init__(self, input_dim, encoder_dim, d_model=128, nhead=4, nlayers=6, dropout=0.1, max_len=1000):\n","        super(TSTransformer, self).__init__()\n","        self.embedding = nn.Linear(input_dim, d_model)\n","        self.pe = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len)\n","        layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n","        self.transformer = nn.TransformerEncoder(layers, num_layers=nlayers)\n","        self.fc = nn.Linear(max_len, encoder_dim)\n","        \n","    def forward(self, x):\n","        x = self.embedding(x) # dim: (B, max_len(288), n_feat(9)) => (B, 288, d_moel(128))\n","        x = self.pe(x) # (288, B, 128)\n","        x = self.transformer(x) # (B, 288, 128)\n","        x = self.fc(x[...,0]) # (B, encoder_dim(1000))\n","        return x\n","    \n","class MyNetwork(nn.Module):\n","    def __init__(self, input_dim, encoder_dim, d_model=128, nhead=4, nlayers=4, num_classes=1, max_len=288):\n","        super(MyNetwork, self).__init__()\n","        self.vit_encoder = ViTEncoder()\n","        self.ts_transformer_encoder = TSTransformer(input_dim=input_dim, encoder_dim=int(encoder_dim/2), d_model=d_model, max_len=max_len)\n","        self.fc1 = nn.Linear(int(768+encoder_dim/4), encoder_dim) #768\n","        self.fc2 = nn.Linear(encoder_dim, encoder_dim)\n","        self.fc3 = nn.Linear(encoder_dim, num_classes)\n","        self.pooling = nn.AvgPool1d(kernel_size=3, stride=2, padding=1)\n","        self.dropout1 = nn.Dropout(0.7)\n","        self.dropout2 = nn.Dropout(0.7)\n","        \n","    def forward(self, img_input, seq_input):\n","        img_feat = self.vit_encoder(img_input) #(B, 768)\n","#         img_feat = self.pooling(img_feat) # (B, 384)\n","        \n","        seq_feat = self.ts_transformer_encoder(seq_input) #(B, 1000)\n","        seq_feat = self.pooling(seq_feat) #(B, 500)\n","        \n","        x = torch.concat([img_feat, seq_feat], axis=1) #(B, 884)\n","        x = self.fc1(x) # (B, 1000)\n","#         x = F.relu(self.fc1(x)) # (B, 1000)\n","#         x = self.dropout1(x)\n","#         x = F.relu(self.fc2(x))\n","#         x = self.dropout2(x)\n","        x = self.fc3(x) # (B, n_classes)\n","\n","        return x\n","\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=1, gamma=2, logits=False, reduce_size=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.logits = logits\n","        self.reduce_size = reduce_size\n","\n","    def forward(self, inputs, targets):\n","    \n","        ce = F.cross_entropy(inputs, targets, reduction='none')\n","        pt = torch.exp(-ce)\n","        fl = self.alpha * (1-pt)**self.gamma * ce\n","\n","        if self.reduce_size:\n","            return torch.mean(fl)\n","        else:\n","            return fl\n","        \n","def seed_everything(seed): # seed 고정\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","\n","seed_everything(seed)"],"metadata":{"id":"w0F51xi_DbRt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"3Ob65BNaD9NX"}},{"cell_type":"code","source":["\n","ray.init(num_gpus=1, ignore_reinit_error=True)\n","\n","@ray.remote(num_gpus=1)\n","class TrainRay(object):\n","    def __init__(self, train_loader, valid_loader, test_loader, input_dim, encoder_dim, d_model, max_len, n_classes, epochs, lr, exp_id, fold_no):\n","        use_cuda = torch.cuda.is_available()\n","        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","        self.train_loader, self.val_loader, self.test_loader = train_loader, valid_loader, test_loader\n","\n","        self.model = MyNetwork(\n","            input_dim=input_dim, encoder_dim=encoder_dim, d_model=d_model, num_classes=n_classes,max_len=max_len\n","        )\n","        if use_cuda:\n","            self.model = self.model.cuda() #to(self.device)\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n","        self.criterion = nn.CrossEntropyLoss() # FocalLoss()#\n","        self.scaler = torch.cuda.amp.GradScaler() \n","        self.epochs = epochs\n","        self.fold_no = fold_no\n","        self.save_path = f\"/usr/src/coco/dacon/lg/data/ckpt/exp_{exp_id}\"\n","        os.makedirs(self.save_path, exist_ok=True)\n","        self.pref_cutoff = 0.91\n","    \n","    def train_epoch(self, batch_item, is_training):\n","        img = batch_item['img'].cuda()#to(self.device)\n","        csv_feature = batch_item['csv_feature'].cuda()#to(self.device)\n","        label = batch_item['label'].cuda()#to(self.device)\n","        if is_training:\n","            self.model.train()\n","            self.optimizer.zero_grad()\n","            with torch.cuda.amp.autocast():\n","                output = self.model(img, csv_feature)\n","                loss = self.criterion(output, label)\n","            \n","            self.scaler.scale(loss).backward()\n","            self.scaler.step(self.optimizer)\n","            self.scaler.update()\n","            \n","            score = self.get_f1(label, output)\n","            return loss, score\n","        else:\n","            self.model.eval()\n","            with torch.no_grad():\n","                with torch.cuda.amp.autocast():\n","                    output = self.model(img, csv_feature)\n","                loss = self.criterion(output, label)\n","            score = self.get_f1(label, output)\n","            return loss, score\n","        \n","    def train(self):\n","        loss_plot, val_loss_plot = [], []\n","        metric_plot, val_metric_plot = [], []\n","\n","        for epoch in range(self.epochs):\n","            total_loss, total_val_loss = 0, 0\n","            total_acc, total_val_acc = 0, 0\n","            \n","            for batch, batch_item in enumerate(self.train_loader):\n","                batch_loss, batch_acc = self.train_epoch(batch_item, True)\n","                total_loss += batch_loss\n","                total_acc += batch_acc\n","            self.scheduler.step()\n","            \n","            print({\n","                'Phase': \"Train\", \n","                'Epoch': epoch + 1,\n","                'Loss' : '{:06f}'.format(total_loss/(batch+1)),\n","                'F-1' : '{:06f}'.format(total_acc/(batch+1))\n","            })\n","            loss_plot.append(total_loss/(batch+1))\n","            metric_plot.append(total_acc/(batch+1))\n","\n","            for batch, batch_item in enumerate(self.val_loader):\n","                batch_loss, batch_acc = self.train_epoch(batch_item, False)\n","                total_val_loss += batch_loss\n","                total_val_acc += batch_acc\n","\n","            print({\n","                'Phase': \"Valid\", \n","                'Epoch': epoch + 1,\n","                'Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n","                'F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n","            })\n","            val_loss_plot.append(total_val_loss/(batch+1))\n","            val_metric_plot.append(total_val_acc/(batch+1))\n","\n","            if np.max(val_metric_plot) == val_metric_plot[-1] and val_metric_plot[-1]>=self.pref_cutoff:\n","#                 torch.save(self.model.state_dict(), f'{self.save_path}/Fold{self.fold_no}_epoch_{epoch}_f1score_{val_metric_plot[-1]}.pth')\n","                torch.save(self.model.state_dict(), f'{self.save_path}/Fold{self.fold_no}.pth')\n","                print(f\"ckpt saved! epoch: {epoch} / val-f1: {val_metric_plot[-1]}\")\n","        return \n","    \n","    def get_f1(self, real, pred):\n","        real = real.cpu()#to(self.device)\n","        pred = torch.argmax(pred, dim=1).cpu()#to(self.device)\n","        score = f1_score(real, pred, average='macro')\n","        return score\n","    \n","    def predict(self):\n","        self.set_best_weights()\n","        self.model.eval()\n","        tqdm_dataset = tqdm(enumerate(self.test_loader))\n","        results = []\n","        for batch, batch_item in tqdm_dataset:\n","            img = batch_item['img'].cuda()\n","            seq = batch_item['csv_feature'].cuda()\n","            with torch.no_grad():\n","                with torch.cuda.amp.autocast():\n","                    output = self.model(img, seq)\n","            output = torch.tensor(torch.argmax(output, dim=1), dtype=torch.int32).cpu().numpy()\n","            results.extend(output)\n","        return results\n","    \n","    def get_weights(self):\n","        return self.model.state_dict()\n","\n","    def set_best_weights(self):\n","        self.model.load_state_dict(torch.load(self.save_path))\n","        print(f\"best model loaded in here: {self.save_path}\")\n","\n","    def save(self):\n","        torch.save(self.model.state_dict(), \"best.pth\")\n","    \n","    def print_gpu_ids(self):\n","        return \"This actor is allowed to use GPUs {}.\".format(ray.get_gpu_ids())\n"],"metadata":{"id":"tkKp3osrDbTz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_fold = 5\n","learning_rate = 3e-5 #1e-4\n","d_model = 512 #256\n","dropout_rate = 0.1\n","epochs = 50\n","input_dim = 24 #9\n","encoder_dim = 2048\n","\n","# train_ray = TrainRay.remote(\n","#     train_loader=train_dataloader, \n","#     valid_loader=val_dataloader,\n","#     test_loader=test_dataloader,\n","#     input_dim=input_dim, encoder_dim=encoder_dim, d_model=d_model, max_len=max_len, \n","#     n_classes=n_classes, epochs=epochs, lr=learning_rate, exp_id=exp_id\n","# )"],"metadata":{"id":"VYIDt2nsDbWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed_everything(seed)\n","skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n","\n","CV_f1, CV_info = [], []\n","fold_no = 1\n","for train_index, val_index in skf.split(X=train, y=labels):\n","    if fold_no >= 1:\n","#         print(labels[train_index].value_counts())\n","#         print(labels[val_index].value_counts())\n","        \n","        trainset = np.array(train)[train_index].tolist()\n","        validset = np.array(train)[val_index].tolist()\n","\n","        train_dataset = CustomDataset(files=trainset, max_len=max_len, transform=train_transform, csv_cols=csv_features)\n","        val_dataset = CustomDataset(files=validset, max_len=max_len, transform=train_transform, csv_cols=csv_features)\n","        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False) \n","\n","        train_ray = TrainRay.remote(\n","            train_loader=train_dataloader, \n","            valid_loader=val_dataloader,\n","            test_loader=None,\n","            input_dim=input_dim, encoder_dim=encoder_dim, d_model=d_model, max_len=max_len, \n","            n_classes=n_classes, epochs=epochs, lr=learning_rate, exp_id=exp_id, fold_no=fold_no\n","        )\n","\n","        print(f\"#==== FOLD {fold_no} ====#\")\n","        ray.get([train_ray.train.remote() for _ in range(1)])\n","        del train_ray\n","    \n","    fold_no +=1\n","    \n","    \n","    print(\"#===================#\")\n","    \n"],"metadata":{"id":"S0mzuMBFDbYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#exp12-1: 0.9156  #d_model 512 -> 256\n","#exp12-2: 0.918   #d_model 256, pe modify #21epoch\n","#exp12-3: 0.915   #d_model 256, embeding_dim 1024, pe modify #15epoch\n","#exp12-4: 0.924   #d_model 512 embeding_dim 2048,  pe modify # epoch ##p100- batch16"],"metadata":{"id":"-rg1mRFXEDAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"fCCmea6dEIyQ"}},{"cell_type":"code","source":["submission = pd.read_csv(f'{data_path}/sample_submission.csv')"],"metadata":{"id":"LG2Ce8pYEDC9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["compose_list = [\n","    transforms.Resize(img_size), \n","    transforms.ColorJitter(brightness=0.5), \n","    transforms.RandomHorizontalFlip(), \n","    transforms.RandomResizedCrop(\n","        img_size, scale=(scale_val, 1), ratio=(scale_val, 1)\n","        ),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","]\n","\n","tta1 = transforms.Compose([compose_list[0]]+compose_list[-2:])\n","tta2 = transforms.Compose(compose_list[:2]+compose_list[-2:])\n","tta3 = transforms.Compose([compose_list[0]]+[compose_list[2]]+compose_list[-2:])\n","# print(tta1, tta2, tta3)"],"metadata":{"id":"GliUH1mUEDGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_dataset = CustomDataset(files=test, max_len=max_len, transform=test_transform, csv_cols=csv_features, mode = 'test')\n","test_dataset = CustomDataset(files=test, max_len=max_len, transform=[tta1, tta2, tta3], csv_cols=csv_features, mode = 'test')\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"x6eLNKPUEK7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy import stats\n","\n","def predict(dataset):\n","    model.eval()\n","    tqdm_dataset = tqdm(enumerate(dataset))\n","    results = []\n","    for batch, batch_item in tqdm_dataset:\n","        img = batch_item['img'].cuda()\n","        seq = batch_item['csv_feature'].cuda()\n","        with torch.no_grad():\n","            output = model(img, seq)\n","        output = torch.tensor(torch.argmax(output, dim=1), dtype=torch.int32).cpu().numpy()\n","        results.extend(output)\n","    return results\n","\n","def predict_tta(dataset):\n","    model.eval()\n","    tqdm_dataset = tqdm(enumerate(dataset))\n","    results = []\n","    for batch, batch_item in tqdm_dataset:\n","        tta_res = []\n","        for im in [\"img\", \"img_tta1\", \"img_tta2\"]:\n","            img = batch_item[im].cuda()\n","            seq = batch_item['csv_feature'].cuda()\n","            with torch.no_grad():\n","                output = model(img, seq)\n","                #print(\"output dim\", output.shape)\n","            unit_output = torch.tensor(torch.argmax(output, dim=1), dtype=torch.int32).cpu().numpy()\n","            #print(\"unit_output dim\", unit_output.shape)\n","            tta_res.append(unit_output)\n","        output = stats.mode(np.array(tta_res))[0][0]\n","        #print(output)\n","        results.extend(output)\n","    return results"],"metadata":{"id":"qlnVw0F0EK-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ckpt_path = f\"{data_path}/ckpt/exp_{exp_id}\"\n","ckpts = [c for c in os.listdir(ckpt_path) if c.endswith(\".pth\")]\n","print(ckpts)"],"metadata":{"id":"3dCginURELCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed_everything(seed)\n","\n","for ckpt in ckpts:\n","    model = MyNetwork(input_dim=input_dim, encoder_dim=encoder_dim, d_model=d_model, num_classes=n_classes,max_len=max_len)\n","    model.load_state_dict(torch.load(f\"{ckpt_path}/{ckpt}\"))\n","    model = model.cuda()\n","    \n","    # preds = predict(test_dataloader)\n","    preds = predict_tta(test_dataloader)\n","    preds = np.array([label_decoder[int(val)] for val in preds])\n","    submission[f\"label_{'_'.join(ckpt.split('_')[:3])}\"] = preds\n","    \n","    model.cpu()\n","    del model"],"metadata":{"id":"XjqjhuaHEPwT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bag_pred = submission.iloc[:, 2:].mode(axis=1)"],"metadata":{"id":"arVJ2RFAEPyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission['label'] = bag_pred[0].values\n","submission.head()"],"metadata":{"id":"NtojlButESPf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission.to_csv(f'{data_path}/result/res_{exp_id}.csv', index=False)"],"metadata":{"id":"B5LhS5jFESWj"},"execution_count":null,"outputs":[]}]}