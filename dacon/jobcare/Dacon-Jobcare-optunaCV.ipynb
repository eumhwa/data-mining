{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dacon_jobcare_optunaCV.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO7nF5zfGWSv/uPMaJVLlvZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IVplpJ3t-J15"},"outputs":[],"source":["#!pip install pytorch-tabnet==3.1.1\n","#!pip install optuna\n","\n","import os\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import json\n","import random \n","from datetime import datetime\n","from typing import List ,Dict, Tuple\n","\n","import numpy as np\n","import pandas as pd\n","# from statsmodels.graphics.mosaicplot import mosaic\n","from matplotlib import pyplot as plt\n","\n","import torch\n","from torch import nn\n","from pytorch_tabnet.tab_model  import TabNetClassifier \n","from pytorch_tabnet.metrics import Metric\n","\n","from sklearn.metrics import f1_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import KFold\n","\n","import optuna\n","from optuna import Trial, visualization\n","from optuna.samplers import TPESampler"],"metadata":{"id":"QAW76nK5-QaG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = \"/content/drive/MyDrive/dacon/data\"\n","train_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n","test_df = pd.read_csv(os.path.join(data_path, 'test.csv'))\n","\n","code_d = pd.read_csv(os.path.join(data_path, '속성_D_코드.csv'))\n","code_h = pd.read_csv(os.path.join(data_path, '속성_H_코드.csv'))\n","code_l = pd.read_csv(os.path.join(data_path, '속성_L_코드.csv'))\n","\n","submission_df = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))"],"metadata":{"id":"eh99WtoH-Qce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["code_d.columns= [\"attribute_d\",\"attribute_d_d\",\"attribute_d_s\",\"attribute_d_m\",\"attribute_d_l\"]\n","code_h.columns= [\"attribute_h\",\"attribute_h_m\",\"attribute_h_l\"]\n","code_l.columns= [\"attribute_l\",\"attribute_l_d\",\"attribute_l_s\",\"attribute_l_m\",\"attribute_l_l\"]\n","\n","print(train_df.shape, test_df.shape, code_d.shape, code_h.shape, code_l.shape)\n","# train_df.head()"],"metadata":{"id":"FG66dBl--Qen"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed_no = 1000\n","\n","def seed_everything(seed): # seed 고정\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","def merge_codes(df:pd.DataFrame, df_code:pd.DataFrame, col:str) -> pd.DataFrame:\n","    df = df.copy()\n","    df_code = df_code.copy()\n","    df_code = df_code.add_prefix(f\"{col}_\")\n","    df_code.columns.values[0] = col\n","    return pd.merge(df, df_code, how=\"left\", on=col)\n","\n","\n","def preprocess_data(\n","    df:pd.DataFrame, is_train:bool=True, \n","    cols_merge:List[Tuple[str,pd.DataFrame]] = [], \n","    cols_equi:List[Tuple[str,str]]= [] ,\n","    cols_drop:List[str] = [\"id\", \"person_prefer_f\", \"person_prefer_g\", \"contents_open_dt\"]\n","    )->Tuple[pd.DataFrame,np.ndarray]:\n","    \n","    df = df.copy()\n","\n","    y_data = None\n","    if is_train:\n","        y_data = df[\"target\"].to_numpy()\n","        df = df.drop(columns=\"target\")\n","\n","    for col, df_code in cols_merge:\n","        df = merge_codes(df, df_code, col)\n","\n","    cols = df.select_dtypes(bool).columns.tolist()\n","    df[cols] = df[cols].astype(int)\n","\n","    for col1, col2 in cols_equi:\n","        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2] ).astype(int)\n","\n","    df = df.drop(columns=cols_drop)\n","    return (df , y_data)\n","\n","# 소분류 중분류 대분류 속성코드 merge 컬럼명 및 데이터 프레임 리스트\n","cols_merge = [\n","              (\"person_prefer_d_1\" , code_d),\n","              (\"person_prefer_d_2\" , code_d),\n","              (\"person_prefer_d_3\" , code_d),\n","              (\"contents_attribute_d\" , code_d),\n","              (\"person_prefer_h_1\" , code_h),\n","              (\"person_prefer_h_2\" , code_h),\n","              (\"person_prefer_h_3\" , code_h),\n","              (\"contents_attribute_h\" , code_h),\n","              (\"contents_attribute_l\" , code_l),\n","]\n","\n","# 회원 속성과 콘텐츠 속성의 동일한 코드 여부에 대한 컬럼명 리스트\n","cols_equi = [\n","    (\"contents_attribute_c\", \"person_prefer_c\"),\n","    (\"contents_attribute_e\", \"person_prefer_e\"),\n","\n","    (\"person_prefer_d_2_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n","    (\"person_prefer_d_2_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n","    (\"person_prefer_d_2_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n","    (\"person_prefer_d_3_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n","    (\"person_prefer_d_3_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n","    (\"person_prefer_d_3_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n","    \n","    (\"person_prefer_h_1_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n","    (\"person_prefer_h_1_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n","    (\"person_prefer_h_2_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n","    (\"person_prefer_h_2_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n","    (\"person_prefer_h_3_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n","    (\"person_prefer_h_3_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n","    \n","    # (\"person_prefer_h_1_attribute_h_p\" , \"contents_attribute_h_attribute_h_p\"),\n","    # (\"person_prefer_h_2_attribute_h_p\" , \"contents_attribute_h_attribute_h_p\"),\n","    # (\"person_prefer_h_3_attribute_h_p\" , \"contents_attribute_h_attribute_h_p\"),\n","]\n","\n","def split_data(x_train, y_train, idx):\n","    X_val = x_train.iloc[idx, ].values\n","    Y_val = y_train[idx]\n","\n","    X_train = x_train.loc[~x_train.index.isin(idx)].values\n","    mask = np.ones(y_train.size, dtype=bool)\n","    mask[idx] = False\n","    Y_train = y_train[mask]\n","\n","    print(X_train.shape, X_val.shape)\n","    print(Y_train.shape, Y_val.shape)\n","    return X_train, Y_train, X_val, Y_val\n","\n","def get_thr(score, gt, n_iter=10000):\n","    f1s = []\n","    for i in range(1, n_iter):\n","        tmp_cutoff = i / n_iter\n","        f1 = f1_score(gt, (score[:, 1]>=tmp_cutoff)*1)\n","        f1s.append(f1)\n","    return f1s.index(max(f1s)) / n_iter, max(f1s)\n","\n","class F1_Score(Metric):\n","    def __init__(self):\n","        self._name = \"f1\"\n","        self._maximize = True\n","\n","    def __call__(self, y_true, y_score):\n","        score = f1_score(y_true, (y_score[:, 1]>0.5)*1)\n","        return score\n","\n","\n","seed_everything(seed_no)"],"metadata":{"id":"stg3bpob-Qgx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df[\"contents_open_mm\"] = train_df[\"contents_open_dt\"].apply(lambda x: pd.Timestamp(x).month)\n","# mosaic(train_df.sort_values('contents_open_mm'), ['contents_open_mm', 'target'], \n","#       title='Mosaic Chart')\n","# plt.show()"],"metadata":{"id":"6Xw5wItq-QjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습에 필요없는 컬럼 리스트\n","cols_drop = [\n","    \"id\",\n","    \"person_prefer_f\", #only one value\n","    \"person_prefer_g\", #only one value\n","    \"contents_open_dt\",\n","    \"person_rn\",\n","    \"contents_rn\"]\n","try: \n","    train_df = train_df.drop(columns=['contents_open_mm']) #mosaic plot\n","except:\n","    print(\"already removed col: contents_open_mm\")\n","\n","x_train, y_train = preprocess_data(train_df, cols_merge = cols_merge , cols_equi= cols_equi , cols_drop = cols_drop)\n","x_test, _ = preprocess_data(test_df,is_train = False, cols_merge = cols_merge , cols_equi= cols_equi  , cols_drop = cols_drop)\n","x_train.shape , y_train.shape , x_test.shape"],"metadata":{"id":"iDcL-WUG-QlC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_idxs = []\n","cat_dims = []\n","ordinal_col = ['person_attribute_a_1', 'person_attribute_b', 'person_prefer_e', 'contents_attribute_e']\n","for idx, col in enumerate(x_train.columns):\n","    if 'match' not in col or col not in ordinal_col: \n","        le = LabelEncoder()\n","        le.fit(x_train[col].values)\n","        le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n","\n","        x_train[col] = x_train[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n","        x_test[col] = x_test[col].apply(lambda x: le_dict.get(x, len(le_dict)))\n","        \n","        cat_idxs.append(idx)\n","        cat_dims.append(len(le_dict)+1)\n","    \n","    if col in ordinal_col:\n","        x_train[col] = x_train[col] / max(x_train[col])\n","        x_test[col] = x_test[col] / max(x_test[col])"],"metadata":{"id":"ub4cbcmJ-Qna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train[ordinal_col].describe()"],"metadata":{"id":"eTCz4mY4-Qps"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TabNet hyperparameter tuning"],"metadata":{"id":"DXGRG0ek-i3n"}},{"cell_type":"code","source":["n_fold_opt = 5\n","n_fold = 10\n","n_trials = 50\n","\n","n_workers = 2\n","patience_cv = 20\n","patience = 50\n","max_epoch = 500\n","lr = 2e-2\n","batch_size = 1024\n","virtual_batch_size = 256\n","time_out_hour = 12\n","eval_metric = ['f1']\n","\n","def Objective(trial):\n","    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n","    n_da = trial.suggest_int(\"n_da\", 32, 64, step=8)\n","    n_steps = trial.suggest_int(\"n_steps\", 1, 5, step=1)\n","    gamma = trial.suggest_float(\"gamma\", 1.1, 1.4, step=0.1)\n","    n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n","    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n","    cat_emb_dim = trial.suggest_int(\"cat_emb_dim\", 1, 5, step=2)\n","    bs = trial.suggest_int(\"batch_size\", virtual_batch_size, 1024, step=virtual_batch_size)\n","    \n","    tabnet_params = dict(\n","        cat_idxs=cat_idxs,\n","        cat_dims=cat_dims,\n","        cat_emb_dim=cat_emb_dim,\n","        n_d=n_da, \n","        n_a=n_da, \n","        n_steps=n_steps, \n","        gamma=gamma,\n","        lambda_sparse=lambda_sparse, \n","        optimizer_fn=torch.optim.AdamW,\n","        optimizer_params=dict(lr=lr),\n","        scheduler_params = {\"gamma\": 0.95, \"step_size\": 10},\n","        mask_type=mask_type, \n","        n_shared=n_shared,\n","        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n","        seed=seed_no,\n","        verbose=0,\n","        ) #early stopping\n","    \n","    kf = KFold(n_splits=n_fold_opt, random_state=seed_no, shuffle=True)\n","    \n","    CV_scores = []\n","    for train_index, test_index in kf.split(x_train.values):\n","        X_train, X_valid = x_train.values[train_index], x_train.values[test_index]\n","        Y_train, Y_valid = y_train[train_index], y_train[test_index]\n","        TabNet = TabNetClassifier(**tabnet_params)\n","        TabNet.fit(\n","            X_train=X_train, \n","            y_train=Y_train,\n","            eval_set=[(X_valid, Y_valid)],\n","            patience=patience_cv,\n","            max_epochs=max_epoch,\n","            eval_metric=eval_metric,\n","            batch_size=bs,\n","            virtual_batch_size=virtual_batch_size,\n","            num_workers=n_workers,\n","            drop_last=False,\n","        )\n","        \n","        CV_scores.append(TabNet.best_cost)\n","    avg = np.mean(CV_scores)\n","    return avg"],"metadata":{"id":"jHlPi3YK-QsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tpe_sampler = TPESampler(seed=seed_no)\n","study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization', sampler=tpe_sampler)\n","# study.optimize(Objective, n_trials=n_trials, timeout=time_out_hour*3600)\n","study.optimize(Objective, n_trials=n_trials)"],"metadata":{"id":"b14IZazV-QuE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optuna.visualization.plot_param_importances(study)"],"metadata":{"id":"S591HaOv-QwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optuna.visualization.plot_optimization_history(study)"],"metadata":{"id":"s4fRufxq-Qye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optuna.visualization.plot_parallel_coordinate(study)"],"metadata":{"id":"4Zt0MJRe-Q3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optuna.visualization.plot_contour(\n","    study,\n","    params=[\n","        \"n_da\", \"cat_emb_dim\", \"n_steps\", \"gamma\", \"lambda_sparse\", \"mask_type\", \"n_shared\"\n","    ],\n",")"],"metadata":{"id":"_ONsYhRh-Q6F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training with CV (Ensemble)"],"metadata":{"id":"5Ru3Zpfy-8kn"}},{"cell_type":"code","source":["TabNet_params = study.best_params\n","final_params = dict(\n","    n_d=TabNet_params['n_da'], \n","    n_a=TabNet_params['n_da'],\n","    cat_emb_dim=TabNet_params['cat_emb_dim'],\n","    n_steps=TabNet_params['n_steps'], \n","    gamma=TabNet_params['gamma'],\n","    lambda_sparse=TabNet_params['lambda_sparse'], \n","    optimizer_fn=torch.optim.AdamW,\n","    mask_type=TabNet_params['mask_type'], \n","    n_shared=TabNet_params['n_shared'],\n","    optimizer_params=dict(lr=lr),\n","    batch_size=TabNet_params[\"batch_size\"]\n","    scheduler_params = {\"gamma\": 0.95, \"step_size\": 10},\n","    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n","    seed=seed_no,\n","    verbose=0,\n",")\n","print(final_params)"],"metadata":{"id":"Q0P-4XNn-Q8S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["strtime = datetime.now().strftime(\"%Y%m%d%H%M\")\n","save_dir = f\"{data_path}/ckpt/{strtime}\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","\n","parameter_path = f'{save_dir}/tuned_params.json'\n","with open(parameter_path, \"w\") as f:\n","    json.dump(final_params, f)"],"metadata":{"id":"w2wXOQ-t-Q_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(parameter_path, \"r\") as json_data:\n","    final_params = json.load(json_data)\n","\n","kf = KFold(n_splits=n_fold, random_state=seed_no, shuffle=True)\n","    \n","CV_f1, CV_info = [], []\n","fold_no = 1\n","for train_index, test_index in kf.split(x_train.values):\n","    train_X, val_X = x_train.values[train_index], x_train.values[test_index]\n","    train_Y, val_Y = y_train[train_index], y_train[test_index]\n","    \n","    final_Tabnet = TabNetClassifier(**final_params)\n","    final_Tabnet.fit(\n","        X_train=train_X, \n","        y_train=train_Y,\n","        eval_set=[(train_X, train_Y), (val_X, val_Y)],\n","        eval_name = ['train', 'val'],\n","        patience=patience,\n","        max_epochs=max_epoch,\n","        eval_metric=eval_metric,\n","        batch_size=final_params[\"batch_size\"], #batch_size,\n","        virtual_batch_size=virtual_batch_size,\n","        num_workers=n_workers,\n","        drop_last=False,\n","    )\n","    \n","    CV_f1.append(final_Tabnet.best_cost)\n","    \n","    val_preds = final_Tabnet.predict_proba(val_X)\n","    best_thr = get_thr(val_preds, val_Y)\n","    print(f'best threshold and f1 score from fold {fold_no}-th validation set : {best_thr}')\n","    \n","    test_preds = final_Tabnet.predict_proba(x_test.values)\n","    test_preds = (test_preds[:,1] >= best_thr[0]) * 1\n","    submission_df[f'target_{fold_no}'] = test_preds\n","    \n","    CV_info.append({'fold':fold_no, 'val_threshold':best_thr[0], 'val_f1':best_thr[1]})\n","    ckpt_path = os.path.join(save_dir, f\"fold_{fold_no}\")\n","    final_Tabnet.save_model(ckpt_path)\n","    fold_no +=1\n","    \n","avg = np.mean(CV_f1)"],"metadata":{"id":"DSunMJMg-6VI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_df.head()"],"metadata":{"id":"kNHYPQ9C_Q-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"laGL0DEc_RNv"},"execution_count":null,"outputs":[]}]}